[03/12 22:24:59] emnist-local-l1-vgg16 INFO: mode: prune
[03/12 22:24:59] emnist-local-l1-vgg16 INFO: model: vgg16
[03/12 22:24:59] emnist-local-l1-vgg16 INFO: verbose: False
[03/12 22:24:59] emnist-local-l1-vgg16 INFO: dataset: emnist
[03/12 22:24:59] emnist-local-l1-vgg16 INFO: batch_size: 128
[03/12 22:24:59] emnist-local-l1-vgg16 INFO: total_epochs: 100
[03/12 22:24:59] emnist-local-l1-vgg16 INFO: lr_decay_milestones: 60,80
[03/12 22:24:59] emnist-local-l1-vgg16 INFO: lr_decay_gamma: 0.1
[03/12 22:24:59] emnist-local-l1-vgg16 INFO: lr: 0.01
[03/12 22:24:59] emnist-local-l1-vgg16 INFO: restore: None
[03/12 22:24:59] emnist-local-l1-vgg16 INFO: output_dir: /home/ravi30/TRUNK_Tutorial_Paper/Monolithic Architectures/VGGPruned/emnist/prune/emnist-local-l1-vgg16
[03/12 22:24:59] emnist-local-l1-vgg16 INFO: method: l1
[03/12 22:24:59] emnist-local-l1-vgg16 INFO: speed_up: 2
[03/12 22:24:59] emnist-local-l1-vgg16 INFO: max_pruning_ratio: 1.0
[03/12 22:24:59] emnist-local-l1-vgg16 INFO: soft_keeping_ratio: 0.0
[03/12 22:24:59] emnist-local-l1-vgg16 INFO: reg: 0.0005
[03/12 22:24:59] emnist-local-l1-vgg16 INFO: delta_reg: 0.0001
[03/12 22:24:59] emnist-local-l1-vgg16 INFO: weight_decay: 0.0005
[03/12 22:24:59] emnist-local-l1-vgg16 INFO: seed: 42
[03/12 22:24:59] emnist-local-l1-vgg16 INFO: global_pruning: False
[03/12 22:24:59] emnist-local-l1-vgg16 INFO: sl_total_epochs: 100
[03/12 22:24:59] emnist-local-l1-vgg16 INFO: sl_lr: 0.01
[03/12 22:24:59] emnist-local-l1-vgg16 INFO: sl_lr_decay_milestones: 60,80
[03/12 22:24:59] emnist-local-l1-vgg16 INFO: sl_reg_warmup: 0
[03/12 22:24:59] emnist-local-l1-vgg16 INFO: sl_restore: None
[03/12 22:24:59] emnist-local-l1-vgg16 INFO: iterative_steps: 400
[03/12 22:24:59] emnist-local-l1-vgg16 INFO: logger: <Logger emnist-local-l1-vgg16 (DEBUG)>
[03/12 22:24:59] emnist-local-l1-vgg16 INFO: device: cuda
[03/12 22:24:59] emnist-local-l1-vgg16 INFO: num_classes: 47
[03/12 22:27:43] emnist-local-l1-vgg16 INFO: mode: prune
[03/12 22:27:43] emnist-local-l1-vgg16 INFO: model: vgg16
[03/12 22:27:43] emnist-local-l1-vgg16 INFO: verbose: False
[03/12 22:27:43] emnist-local-l1-vgg16 INFO: dataset: emnist
[03/12 22:27:43] emnist-local-l1-vgg16 INFO: batch_size: 128
[03/12 22:27:43] emnist-local-l1-vgg16 INFO: total_epochs: 100
[03/12 22:27:43] emnist-local-l1-vgg16 INFO: lr_decay_milestones: 60,80
[03/12 22:27:43] emnist-local-l1-vgg16 INFO: lr_decay_gamma: 0.1
[03/12 22:27:43] emnist-local-l1-vgg16 INFO: lr: 0.01
[03/12 22:27:43] emnist-local-l1-vgg16 INFO: restore: None
[03/12 22:27:43] emnist-local-l1-vgg16 INFO: output_dir: /home/ravi30/TRUNK_Tutorial_Paper/Monolithic Architectures/VGGPruned/emnist/prune/emnist-local-l1-vgg16
[03/12 22:27:43] emnist-local-l1-vgg16 INFO: method: l1
[03/12 22:27:43] emnist-local-l1-vgg16 INFO: speed_up: 2
[03/12 22:27:43] emnist-local-l1-vgg16 INFO: max_pruning_ratio: 1.0
[03/12 22:27:43] emnist-local-l1-vgg16 INFO: soft_keeping_ratio: 0.0
[03/12 22:27:43] emnist-local-l1-vgg16 INFO: reg: 0.0005
[03/12 22:27:43] emnist-local-l1-vgg16 INFO: delta_reg: 0.0001
[03/12 22:27:43] emnist-local-l1-vgg16 INFO: weight_decay: 0.0005
[03/12 22:27:43] emnist-local-l1-vgg16 INFO: seed: 42
[03/12 22:27:43] emnist-local-l1-vgg16 INFO: global_pruning: False
[03/12 22:27:43] emnist-local-l1-vgg16 INFO: sl_total_epochs: 100
[03/12 22:27:43] emnist-local-l1-vgg16 INFO: sl_lr: 0.01
[03/12 22:27:43] emnist-local-l1-vgg16 INFO: sl_lr_decay_milestones: 60,80
[03/12 22:27:43] emnist-local-l1-vgg16 INFO: sl_reg_warmup: 0
[03/12 22:27:43] emnist-local-l1-vgg16 INFO: sl_restore: None
[03/12 22:27:43] emnist-local-l1-vgg16 INFO: iterative_steps: 400
[03/12 22:27:43] emnist-local-l1-vgg16 INFO: logger: <Logger emnist-local-l1-vgg16 (DEBUG)>
[03/12 22:27:43] emnist-local-l1-vgg16 INFO: device: cuda
[03/12 22:27:43] emnist-local-l1-vgg16 INFO: num_classes: 47
[03/12 22:29:21] emnist-local-l1-vgg16 INFO: mode: prune
[03/12 22:29:21] emnist-local-l1-vgg16 INFO: model: vgg16
[03/12 22:29:21] emnist-local-l1-vgg16 INFO: verbose: False
[03/12 22:29:21] emnist-local-l1-vgg16 INFO: dataset: emnist
[03/12 22:29:21] emnist-local-l1-vgg16 INFO: batch_size: 128
[03/12 22:29:21] emnist-local-l1-vgg16 INFO: total_epochs: 100
[03/12 22:29:21] emnist-local-l1-vgg16 INFO: lr_decay_milestones: 60,80
[03/12 22:29:21] emnist-local-l1-vgg16 INFO: lr_decay_gamma: 0.1
[03/12 22:29:21] emnist-local-l1-vgg16 INFO: lr: 0.01
[03/12 22:29:21] emnist-local-l1-vgg16 INFO: restore: None
[03/12 22:29:21] emnist-local-l1-vgg16 INFO: output_dir: /home/ravi30/TRUNK_Tutorial_Paper/Monolithic Architectures/VGGPruned/emnist/prune/emnist-local-l1-vgg16
[03/12 22:29:21] emnist-local-l1-vgg16 INFO: method: l1
[03/12 22:29:21] emnist-local-l1-vgg16 INFO: speed_up: 2
[03/12 22:29:21] emnist-local-l1-vgg16 INFO: max_pruning_ratio: 1.0
[03/12 22:29:21] emnist-local-l1-vgg16 INFO: soft_keeping_ratio: 0.0
[03/12 22:29:21] emnist-local-l1-vgg16 INFO: reg: 0.0005
[03/12 22:29:21] emnist-local-l1-vgg16 INFO: delta_reg: 0.0001
[03/12 22:29:21] emnist-local-l1-vgg16 INFO: weight_decay: 0.0005
[03/12 22:29:21] emnist-local-l1-vgg16 INFO: seed: 42
[03/12 22:29:21] emnist-local-l1-vgg16 INFO: global_pruning: False
[03/12 22:29:21] emnist-local-l1-vgg16 INFO: sl_total_epochs: 100
[03/12 22:29:21] emnist-local-l1-vgg16 INFO: sl_lr: 0.01
[03/12 22:29:21] emnist-local-l1-vgg16 INFO: sl_lr_decay_milestones: 60,80
[03/12 22:29:21] emnist-local-l1-vgg16 INFO: sl_reg_warmup: 0
[03/12 22:29:21] emnist-local-l1-vgg16 INFO: sl_restore: None
[03/12 22:29:21] emnist-local-l1-vgg16 INFO: iterative_steps: 400
[03/12 22:29:21] emnist-local-l1-vgg16 INFO: logger: <Logger emnist-local-l1-vgg16 (DEBUG)>
[03/12 22:29:21] emnist-local-l1-vgg16 INFO: device: cuda
[03/12 22:29:21] emnist-local-l1-vgg16 INFO: num_classes: 47
[03/12 22:29:48] emnist-local-l1-vgg16 INFO: Pruning...
[03/12 22:29:55] emnist-local-l1-vgg16 INFO: VGG(
  (block0): Sequential(
    (0): Conv2d(1, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block1): Sequential(
    (0): Conv2d(45, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(90, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(90, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block2): Sequential(
    (0): Conv2d(90, 181, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(181, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(181, 181, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(181, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(181, 181, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(181, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block3): Sequential(
    (0): Conv2d(181, 362, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(362, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(362, 362, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(362, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(362, 362, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(362, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block4): Sequential(
    (0): Conv2d(362, 362, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(362, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(362, 362, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(362, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(362, 362, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(362, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool4): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=362, out_features=47, bias=True)
)
[03/12 22:30:18] emnist-local-l1-vgg16 INFO: Params: 14.75 M => 7.38 M (50.03%)
[03/12 22:30:18] emnist-local-l1-vgg16 INFO: FLOPs: 19508.05 M => 9741.53 M (49.94%, 2.00X )
[03/12 22:30:18] emnist-local-l1-vgg16 INFO: Acc: 0.0212 => 0.0213
[03/12 22:30:18] emnist-local-l1-vgg16 INFO: Val Loss: 3.8501 => 3.8501
[03/12 22:30:18] emnist-local-l1-vgg16 INFO: Finetuning...
[03/12 22:34:18] emnist-local-l1-vgg16 INFO: mode: prune
[03/12 22:34:18] emnist-local-l1-vgg16 INFO: model: vgg16
[03/12 22:34:18] emnist-local-l1-vgg16 INFO: verbose: False
[03/12 22:34:18] emnist-local-l1-vgg16 INFO: dataset: emnist
[03/12 22:34:18] emnist-local-l1-vgg16 INFO: batch_size: 128
[03/12 22:34:18] emnist-local-l1-vgg16 INFO: total_epochs: 100
[03/12 22:34:18] emnist-local-l1-vgg16 INFO: lr_decay_milestones: 60,80
[03/12 22:34:18] emnist-local-l1-vgg16 INFO: lr_decay_gamma: 0.1
[03/12 22:34:18] emnist-local-l1-vgg16 INFO: lr: 0.01
[03/12 22:34:18] emnist-local-l1-vgg16 INFO: restore: None
[03/12 22:34:18] emnist-local-l1-vgg16 INFO: output_dir: /home/ravi30/TRUNK_Tutorial_Paper/Monolithic Architectures/VGGPruned/emnist/prune/emnist-local-l1-vgg16
[03/12 22:34:18] emnist-local-l1-vgg16 INFO: method: l1
[03/12 22:34:18] emnist-local-l1-vgg16 INFO: speed_up: 2
[03/12 22:34:18] emnist-local-l1-vgg16 INFO: max_pruning_ratio: 1.0
[03/12 22:34:18] emnist-local-l1-vgg16 INFO: soft_keeping_ratio: 0.0
[03/12 22:34:18] emnist-local-l1-vgg16 INFO: reg: 0.0005
[03/12 22:34:18] emnist-local-l1-vgg16 INFO: delta_reg: 0.0001
[03/12 22:34:18] emnist-local-l1-vgg16 INFO: weight_decay: 0.0005
[03/12 22:34:18] emnist-local-l1-vgg16 INFO: seed: 42
[03/12 22:34:18] emnist-local-l1-vgg16 INFO: global_pruning: False
[03/12 22:34:18] emnist-local-l1-vgg16 INFO: sl_total_epochs: 100
[03/12 22:34:18] emnist-local-l1-vgg16 INFO: sl_lr: 0.01
[03/12 22:34:18] emnist-local-l1-vgg16 INFO: sl_lr_decay_milestones: 60,80
[03/12 22:34:18] emnist-local-l1-vgg16 INFO: sl_reg_warmup: 0
[03/12 22:34:18] emnist-local-l1-vgg16 INFO: sl_restore: None
[03/12 22:34:18] emnist-local-l1-vgg16 INFO: iterative_steps: 400
[03/12 22:34:18] emnist-local-l1-vgg16 INFO: logger: <Logger emnist-local-l1-vgg16 (DEBUG)>
[03/12 22:34:18] emnist-local-l1-vgg16 INFO: device: cuda
[03/12 22:34:18] emnist-local-l1-vgg16 INFO: num_classes: 47
[03/12 22:34:45] emnist-local-l1-vgg16 INFO: Pruning...
[03/12 22:34:51] emnist-local-l1-vgg16 INFO: VGG(
  (block0): Sequential(
    (0): Conv2d(1, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block1): Sequential(
    (0): Conv2d(45, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(90, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(90, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block2): Sequential(
    (0): Conv2d(90, 181, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(181, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(181, 181, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(181, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(181, 181, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(181, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block3): Sequential(
    (0): Conv2d(181, 362, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(362, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(362, 362, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(362, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(362, 362, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(362, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block4): Sequential(
    (0): Conv2d(362, 362, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(362, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(362, 362, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(362, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(362, 362, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(362, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool4): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=362, out_features=47, bias=True)
)
[03/12 22:35:13] emnist-local-l1-vgg16 INFO: Params: 14.75 M => 7.38 M (50.03%)
[03/12 22:35:13] emnist-local-l1-vgg16 INFO: FLOPs: 19508.05 M => 9741.53 M (49.94%, 2.00X )
[03/12 22:35:13] emnist-local-l1-vgg16 INFO: Acc: 0.0212 => 0.0213
[03/12 22:35:13] emnist-local-l1-vgg16 INFO: Val Loss: 3.8501 => 3.8501
[03/12 22:35:13] emnist-local-l1-vgg16 INFO: Finetuning...
[03/12 22:36:08] emnist-local-l1-vgg16 INFO: mode: prune
[03/12 22:36:08] emnist-local-l1-vgg16 INFO: model: vgg16
[03/12 22:36:08] emnist-local-l1-vgg16 INFO: verbose: False
[03/12 22:36:08] emnist-local-l1-vgg16 INFO: dataset: emnist
[03/12 22:36:08] emnist-local-l1-vgg16 INFO: batch_size: 128
[03/12 22:36:08] emnist-local-l1-vgg16 INFO: total_epochs: 100
[03/12 22:36:08] emnist-local-l1-vgg16 INFO: lr_decay_milestones: 60,80
[03/12 22:36:08] emnist-local-l1-vgg16 INFO: lr_decay_gamma: 0.1
[03/12 22:36:08] emnist-local-l1-vgg16 INFO: lr: 0.01
[03/12 22:36:08] emnist-local-l1-vgg16 INFO: restore: None
[03/12 22:36:08] emnist-local-l1-vgg16 INFO: output_dir: /home/ravi30/TRUNK_Tutorial_Paper/Monolithic Architectures/VGGPruned/emnist/prune/emnist-local-l1-vgg16
[03/12 22:36:08] emnist-local-l1-vgg16 INFO: method: l1
[03/12 22:36:08] emnist-local-l1-vgg16 INFO: speed_up: 2
[03/12 22:36:08] emnist-local-l1-vgg16 INFO: max_pruning_ratio: 1.0
[03/12 22:36:08] emnist-local-l1-vgg16 INFO: soft_keeping_ratio: 0.0
[03/12 22:36:08] emnist-local-l1-vgg16 INFO: reg: 0.0005
[03/12 22:36:08] emnist-local-l1-vgg16 INFO: delta_reg: 0.0001
[03/12 22:36:08] emnist-local-l1-vgg16 INFO: weight_decay: 0.0005
[03/12 22:36:08] emnist-local-l1-vgg16 INFO: seed: 42
[03/12 22:36:08] emnist-local-l1-vgg16 INFO: global_pruning: False
[03/12 22:36:08] emnist-local-l1-vgg16 INFO: sl_total_epochs: 100
[03/12 22:36:08] emnist-local-l1-vgg16 INFO: sl_lr: 0.01
[03/12 22:36:08] emnist-local-l1-vgg16 INFO: sl_lr_decay_milestones: 60,80
[03/12 22:36:08] emnist-local-l1-vgg16 INFO: sl_reg_warmup: 0
[03/12 22:36:08] emnist-local-l1-vgg16 INFO: sl_restore: None
[03/12 22:36:08] emnist-local-l1-vgg16 INFO: iterative_steps: 400
[03/12 22:36:08] emnist-local-l1-vgg16 INFO: logger: <Logger emnist-local-l1-vgg16 (DEBUG)>
[03/12 22:36:08] emnist-local-l1-vgg16 INFO: device: cuda
[03/12 22:36:08] emnist-local-l1-vgg16 INFO: num_classes: 47
[03/12 22:36:35] emnist-local-l1-vgg16 INFO: Pruning...
[03/12 22:36:43] emnist-local-l1-vgg16 INFO: VGG(
  (block0): Sequential(
    (0): Conv2d(1, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block1): Sequential(
    (0): Conv2d(45, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(90, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(90, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block2): Sequential(
    (0): Conv2d(90, 181, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(181, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(181, 181, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(181, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(181, 181, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(181, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block3): Sequential(
    (0): Conv2d(181, 362, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(362, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(362, 362, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(362, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(362, 362, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(362, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block4): Sequential(
    (0): Conv2d(362, 362, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(362, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(362, 362, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(362, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(362, 362, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(362, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool4): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=362, out_features=47, bias=True)
)
[03/12 22:37:05] emnist-local-l1-vgg16 INFO: Params: 14.75 M => 7.38 M (50.03%)
[03/12 22:37:05] emnist-local-l1-vgg16 INFO: FLOPs: 19508.05 M => 9741.53 M (49.94%, 2.00X )
[03/12 22:37:05] emnist-local-l1-vgg16 INFO: Acc: 0.0212 => 0.0213
[03/12 22:37:05] emnist-local-l1-vgg16 INFO: Val Loss: 3.8501 => 3.8501
[03/12 22:37:05] emnist-local-l1-vgg16 INFO: Finetuning...
[03/12 22:44:53] emnist-local-l1-vgg16 INFO: Epoch 0/100, Acc=0.8209, Val Loss=0.6085, lr=0.0100
[03/12 22:52:42] emnist-local-l1-vgg16 INFO: Epoch 1/100, Acc=0.8430, Val Loss=0.4929, lr=0.0100
[03/12 23:00:31] emnist-local-l1-vgg16 INFO: Epoch 2/100, Acc=0.8508, Val Loss=0.4651, lr=0.0100
[03/12 23:08:20] emnist-local-l1-vgg16 INFO: Epoch 3/100, Acc=0.8510, Val Loss=0.4412, lr=0.0100
[03/12 23:16:09] emnist-local-l1-vgg16 INFO: Epoch 4/100, Acc=0.8741, Val Loss=0.3728, lr=0.0100
[03/12 23:23:58] emnist-local-l1-vgg16 INFO: Epoch 5/100, Acc=0.8683, Val Loss=0.3949, lr=0.0100
[03/12 23:31:46] emnist-local-l1-vgg16 INFO: Epoch 6/100, Acc=0.8882, Val Loss=0.3330, lr=0.0100
[03/12 23:39:35] emnist-local-l1-vgg16 INFO: Epoch 7/100, Acc=0.8886, Val Loss=0.3235, lr=0.0100
[03/12 23:47:24] emnist-local-l1-vgg16 INFO: Epoch 8/100, Acc=0.8893, Val Loss=0.3350, lr=0.0100
[03/12 23:55:13] emnist-local-l1-vgg16 INFO: Epoch 9/100, Acc=0.8307, Val Loss=0.5050, lr=0.0100
[03/13 00:03:02] emnist-local-l1-vgg16 INFO: Epoch 10/100, Acc=0.8893, Val Loss=0.3124, lr=0.0100
[03/13 00:10:51] emnist-local-l1-vgg16 INFO: Epoch 11/100, Acc=0.8905, Val Loss=0.3211, lr=0.0100
[03/13 00:18:40] emnist-local-l1-vgg16 INFO: Epoch 12/100, Acc=0.8932, Val Loss=0.3099, lr=0.0100
[03/13 00:26:28] emnist-local-l1-vgg16 INFO: Epoch 13/100, Acc=0.8918, Val Loss=0.3187, lr=0.0100
[03/13 00:34:17] emnist-local-l1-vgg16 INFO: Epoch 14/100, Acc=0.8943, Val Loss=0.3031, lr=0.0100
[03/13 00:42:06] emnist-local-l1-vgg16 INFO: Epoch 15/100, Acc=0.8904, Val Loss=0.3182, lr=0.0100
[03/13 00:49:55] emnist-local-l1-vgg16 INFO: Epoch 16/100, Acc=0.8970, Val Loss=0.3072, lr=0.0100
[03/13 00:57:44] emnist-local-l1-vgg16 INFO: Epoch 17/100, Acc=0.8865, Val Loss=0.3248, lr=0.0100
[03/13 01:05:32] emnist-local-l1-vgg16 INFO: Epoch 18/100, Acc=0.8863, Val Loss=0.3349, lr=0.0100
[03/13 01:13:21] emnist-local-l1-vgg16 INFO: Epoch 19/100, Acc=0.8918, Val Loss=0.3189, lr=0.0100
[03/13 01:21:10] emnist-local-l1-vgg16 INFO: Epoch 20/100, Acc=0.8984, Val Loss=0.2961, lr=0.0100
[03/13 01:28:59] emnist-local-l1-vgg16 INFO: Epoch 21/100, Acc=0.8985, Val Loss=0.2966, lr=0.0100
[03/13 01:36:48] emnist-local-l1-vgg16 INFO: Epoch 22/100, Acc=0.8752, Val Loss=0.3952, lr=0.0100
[03/13 01:44:37] emnist-local-l1-vgg16 INFO: Epoch 23/100, Acc=0.8863, Val Loss=0.3355, lr=0.0100
[03/13 01:52:25] emnist-local-l1-vgg16 INFO: Epoch 24/100, Acc=0.8808, Val Loss=0.3514, lr=0.0100
[03/13 02:00:14] emnist-local-l1-vgg16 INFO: Epoch 25/100, Acc=0.8734, Val Loss=0.3843, lr=0.0100
[03/13 02:08:03] emnist-local-l1-vgg16 INFO: Epoch 26/100, Acc=0.8848, Val Loss=0.3156, lr=0.0100
[03/13 02:15:52] emnist-local-l1-vgg16 INFO: Epoch 27/100, Acc=0.8960, Val Loss=0.3069, lr=0.0100
[03/13 02:23:41] emnist-local-l1-vgg16 INFO: Epoch 28/100, Acc=0.8909, Val Loss=0.3270, lr=0.0100
[03/13 02:31:30] emnist-local-l1-vgg16 INFO: Epoch 29/100, Acc=0.8821, Val Loss=0.3458, lr=0.0100
