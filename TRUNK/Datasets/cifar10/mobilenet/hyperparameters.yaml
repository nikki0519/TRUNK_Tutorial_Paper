seed: 42
dataset:
  train:
    params:
      batch_size: 16
      num_workers: 1
      shuffle: True
    transform:
    - type: RandomCrop
      params:
        size:
        - 32
        - 32
        padding: 4
    - type: Resize
      params:
        size:
        - 224
        - 224
    - type: RandomHorizontalFlip
    - type: ToTensor
    - type: Normalize
      params:
        mean:
        - 0.4914
        - 0.4822
        - 0.4465
        std:
        - 0.2023
        - 0.1994
        - 0.2010
  validation:
    params:
      batch_size: 16
      num_workers: 1
      shuffle: True
    transform:
    - type: RandomCrop
      params:
        size:
        - 32
        - 32
        padding: 4
    - type: Resize
      params:
        size:
        - 224
        - 224
    - type: RandomHorizontalFlip
    - type: ToTensor
    - type: Normalize
      params:
        mean:
        - 0.4914
        - 0.4822
        - 0.4465
        std:
        - 0.2023
        - 0.1994
        - 0.2010
  test:
    params:
      batch_size: 1
      num_workers: 1
      shuffle: True
general:
  class_hyperparameters:
    loss: 
    - type: NLLLoss
    lr_scheduler: 
    - type: CosineAnnealingLR
      params:
        T_max: 10
        eta_min: 0
    optimizer: 
    - type: Adam
      params:
        lr: 0.001
        weight_decay: 0.0001
    epochs: 10
  grouping_hyperparameters:
    loss: 
    - type: NLLLoss
    grouping_volatility: 0.85
    lr_scheduler: 
    - type: CosineAnnealingLR
      params:
        T_max: 10
        eta_min: 0
    optimizer: 
    - type: Adam
      params:
        lr: 0.001
        weight_decay: 0.0005
    epochs: 45
sg1:
  class_hyperparameters:
    loss: 
    - type: NLLLoss
    lr_scheduler: 
    - type: CosineAnnealingLR
      params:
        T_max: 10
        eta_min: 0
    optimizer: 
    - type: Adam
      params:
        lr: 0.001
        weight_decay: 0.0001
    epochs: 5
  grouping_hyperparameters:
    loss: 
    - type: NLLLoss
    grouping_volatility: 0.85
    lr_scheduler: 
    - type: CosineAnnealingLR
      params:
        T_max: 10
        eta_min: 0
    optimizer: 
    - type: Adam
      params:
        lr: 0.001
        weight_decay: 0.0005
    epochs: 45
sg2:
  class_hyperparameters:
    loss: 
    - type: NLLLoss
    lr_scheduler: 
    - type: CosineAnnealingLR
      params:
        T_max: 10
        eta_min: 0
    optimizer: 
    - type: Adam
      params:
        lr: 0.001
        weight_decay: 0.0001
    epochs: 10
  grouping_hyperparameters:
    loss: 
    - type: NLLLoss
    grouping_volatility: 0.85
    lr_scheduler: 
    - type: CosineAnnealingLR
      params:
        T_max: 10
        eta_min: 0
    optimizer: 
    - type: Adam
      params:
        lr: 0.001
        weight_decay: 0.0005
    epochs: 60
sg4:
  class_hyperparameters:
    loss: 
    - type: NLLLoss
    lr_scheduler: 
    - type: CosineAnnealingLR
      params:
        T_max: 10
        eta_min: 0
    optimizer: 
    - type: Adam
      params:
        lr: 0.0001
        weight_decay: 0.0005
    epochs: 12
  grouping_hyperparameters:
    loss: 
    - type: NLLLoss
    grouping_volatility: 0.78
    lr_scheduler: 
    - type: CosineAnnealingLR
      params:
        T_max: 10
        eta_min: 0
    optimizer: 
    - type: Adam
      params:
        lr: 0.0001
        weight_decay: 0.0005
    epochs: 60
sg5:
  class_hyperparameters:
    loss: 
    - type: NLLLoss
    lr_scheduler: 
    - type: CosineAnnealingLR
      params:
        T_max: 10
        eta_min: 0
    optimizer: 
    - type: Adam
      params:
        lr: 0.0002
        weight_decay: 0.0005
    epochs: 40
  grouping_hyperparameters:
    loss: 
    - type: NLLLoss
    grouping_volatility: 0.95
    lr_scheduler: 
    - type: CosineAnnealingLR
      params:
        T_max: 10
        eta_min: 0
    optimizer: 
    - type: Adam
      params:
        lr: 0.0002
        weight_decay: 0.0005
    epochs: 120
sg15:
  class_hyperparameters:
    loss: 
    - type: NLLLoss
    lr_scheduler: 
    - type: CosineAnnealingLR
      params:
        T_max: 10
        eta_min: 0
    optimizer: 
    - type: Adam
      params:
        lr: 0.0002
        weight_decay: 0.0005
    epochs: 40
  grouping_hyperparameters:
    loss: 
    - type: NLLLoss
    grouping_volatility: 0.95
    lr_scheduler: 
    - type: CosineAnnealingLR
      params:
        T_max: 10
        eta_min: 0
    optimizer: 
    - type: Adam
      params:
        lr: 0.0002
        weight_decay: 0.0005
    epochs: 60
retrain: